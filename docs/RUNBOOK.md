# Runbook OpÃ©rationnel - Paris Sportif Backend

**Version:** 1.0  
**DerniÃ¨re mise Ã  jour:** 5 fÃ©vrier 2026  
**Mainteneur:** DevOps Team

---

## Table des MatiÃ¨res

1. [Contacts & AccÃ¨s](#contacts--accÃ¨s)
2. [ProcÃ©dures Standard](#procÃ©dures-standard)
3. [ScÃ©narios d'Incident](#scÃ©narios-dincident)
4. [Maintenance PlanifiÃ©e](#maintenance-planifiÃ©e)
5. [Checklists](#checklists)

---

## Contacts & AccÃ¨s

### Ã‰quipe
- **On-Call Primary:** DevOps Team
- **On-Call Secondary:** Backend Team
- **Escalation:** CTO

### Dashboards
- **Render Dashboard:** https://dashboard.render.com/web/srv-xxx
- **Upstash Redis:** https://console.upstash.com/redis/xxx
- **Qdrant Cloud:** https://cloud.qdrant.io/
- **Sentry:** https://sentry.io/organizations/paris-sportif/
- **Uptime Robot:** https://uptimerobot.com/dashboard (Ã  configurer)

### Endpoints de Monitoring
- **Production API:** https://paris-sportif-api.onrender.com
- **Health Check:** https://paris-sportif-api.onrender.com/health
- **Dependencies Check:** https://paris-sportif-api.onrender.com/health/ready
- **OpenAPI Docs:** https://paris-sportif-api.onrender.com/docs

---

## ProcÃ©dures Standard

### 1. VÃ©rifier l'Ã‰tat du SystÃ¨me

```bash
# Health check basique
curl https://paris-sportif-api.onrender.com/health

# VÃ©rifier toutes les dÃ©pendances
curl https://paris-sportif-api.onrender.com/health/ready | jq .

# Exemple de rÃ©ponse saine:
# {
#   "status": "ready",
#   "database": true,
#   "redis": true,
#   "football_api": true,
#   "llm_api": true  # Doit Ãªtre true si ANTHROPIC_API_KEY configurÃ©
# }
```

### 2. Consulter les Logs

**Via Render Dashboard:**
1. Go to https://dashboard.render.com
2. Select `paris-sportif-api` service
3. Click "Logs" tab
4. Filter by level: `ERROR`, `WARNING`, `INFO`

**Patterns de Logs Communs:**
```bash
# Erreurs de connexion DB
grep "connection pool" logs.txt

# Erreurs Redis
grep "Redis" logs.txt | grep "ERROR"

# Rate limits API Football
grep "RateLimitError" logs.txt

# Erreurs LLM
grep "GROQ\|Anthropic" logs.txt | grep "ERROR"
```

### 3. DÃ©ploiement & Rollback

**DÃ©ployer Manuellement:**
```bash
# Trigger deploy via Git push
git push origin main

# Ou via Render Deploy Hook (curl)
curl -X POST "$RENDER_DEPLOY_HOOK_URL"
```

**Rollback en Cas d'Erreur:**
1. Render Dashboard â†’ Service â†’ "Deploys" tab
2. Find last working deploy (status: "Live")
3. Click "..." â†’ "Redeploy"
4. Confirm rollback
5. Monitor logs for 5 minutes

**Temps estimÃ©:** 5-10 minutes

---

## ScÃ©narios d'Incident

### Incident 1: API ComplÃ¨tement Down (HTTP 503)

**SymptÃ´mes:**
- `/health` retourne 503 Service Unavailable
- Frontend affiche "Service temporairement indisponible"
- Render Dashboard: Service status "Unhealthy"

**Causes Possibles:**
1. Deploy en cours (normal, 30-60s downtime)
2. Service crashÃ© (OOM, exception non catchÃ©e)
3. Database unreachable
4. Code error au startup (migration failed)

**Diagnostic:**
```bash
# 1. VÃ©rifier status Render
# Dashboard â†’ Status indicator (rouge = down)

# 2. VÃ©rifier logs startup
# Dashboard â†’ Logs â†’ Filter "ERROR" or "CRITICAL"

# 3. VÃ©rifier DB connectivity
curl https://paris-sportif-api.onrender.com/health/ready
# Si "database": false â†’ DB issue
```

**Actions:**
1. **Si deploy en cours:** Attendre 2 minutes, service devrait redÃ©marrer
2. **Si service crashÃ©:**
   ```bash
   # Restart manual
   # Dashboard â†’ Settings â†’ "Manual Deploy"
   # Ou rollback au dernier deploy stable
   ```
3. **Si DB unreachable:**
   - VÃ©rifier Render PostgreSQL status
   - Dashboard â†’ Database â†’ Metrics
   - Si DB down: Contacter Render Support
4. **Si code error:**
   - Rollback au dernier commit stable
   - Fix bug en urgence sur branche `hotfix/xxx`
   - Deploy fix

**Temps de RÃ©solution:** 5-15 minutes  
**PrioritÃ©:** ðŸ”´ P0 (Critical)

---

### Incident 2: API Lente (Response Time > 2s)

**SymptÃ´mes:**
- Health check OK mais lent (>500ms)
- Frontend timeouts sur certaines requÃªtes
- Utilisateurs se plaignent de lenteur

**Causes Possibles:**
1. DB query lente (missing index, full table scan)
2. Cache Redis miss (pas de hit)
3. API externe timeout (Football Data, Groq)
4. CPU/Memory exhaustion
5. Connection pool exhaustion

**Diagnostic:**
```bash
# 1. Identifier endpoints lents via Sentry APM
# Sentry â†’ Performance â†’ Transactions â†’ Sort by "p95"

# 2. VÃ©rifier mÃ©triques serveur
# Render Dashboard â†’ Metrics
# - CPU > 80% ? â†’ Scale up needed
# - Memory > 400MB ? â†’ Memory leak or load spike

# 3. Tester requÃªte problÃ©matique
curl -w "\nTime: %{time_total}s\n" \
  https://paris-sportif-api.onrender.com/api/v1/predictions?limit=10
```

**Actions:**
1. **Query DB lente:**
   ```sql
   -- Identifier queries lentes (PostgreSQL)
   SELECT query, calls, mean_exec_time, max_exec_time
   FROM pg_stat_statements
   ORDER BY mean_exec_time DESC
   LIMIT 10;
   ```
   - Ajouter index manquant
   - Optimiser query (EXPLAIN ANALYZE)

2. **Cache miss:**
   ```python
   # VÃ©rifier hit rate Redis
   # Upstash Dashboard â†’ Metrics â†’ Hit Rate
   # Si < 50% â†’ augmenter TTL cache
   ```

3. **API externe timeout:**
   - VÃ©rifier status page API externe
   - Augmenter timeout si nÃ©cessaire
   - ImplÃ©menter retry avec backoff

4. **CPU/Memory exhaustion:**
   ```bash
   # Scale up temporairement
   # Render Dashboard â†’ Settings â†’ Instance Type
   # Standard â†’ Pro (plus de CPU/RAM)
   ```

5. **Connection pool exhaustion:**
   ```python
   # Fix: Augmenter pool size dans src/db/database.py
   engine = create_async_engine(
       settings.database_url,
       pool_size=20,  # 5 â†’ 20
       max_overflow=10,
   )
   ```

**Temps de RÃ©solution:** 15-60 minutes  
**PrioritÃ©:** ðŸŸ  P1 (High)

---

### Incident 3: Rate Limit Exceeded (Football Data API)

**SymptÃ´mes:**
- Logs: `RateLimitError: API rate limit exceeded`
- Scheduler job `auto_sync_and_verify` failed
- Matches data pas Ã  jour

**Causes:**
- DÃ©passement du plan Free (10 req/min)
- Trop de syncs simultanÃ©s
- Spike de traffic utilisateur

**Diagnostic:**
```bash
# VÃ©rifier logs scheduler
# Render Dashboard â†’ Logs â†’ Search "RateLimitError"

# VÃ©rifier plan API
# https://www.football-data.org/client/home
# â†’ Usage â†’ Requests today
```

**Actions:**
1. **RÃ©duire frÃ©quence sync:**
   ```python
   # src/api/main.py - Ligne 193
   scheduler.add_job(
       auto_sync_and_verify,
       trigger=IntervalTrigger(hours=12),  # 6h â†’ 12h
   )
   # Deploy fix
   ```

2. **Upgrade plan API (si nÃ©cessaire):**
   - Free: 10 req/min
   - Tier One: â‚¬15/mois, 600 req/min
   - Tier Two: â‚¬50/mois, 10 req/sec

3. **ImplÃ©menter rate limiting interne:**
   ```python
   # Ajouter dans src/data/sources/football_data.py
   import asyncio
   
   async def _request(self, method, endpoint):
       await asyncio.sleep(0.5)  # 120 req/min max
       # ... existing code
   ```

**Temps de RÃ©solution:** 5 minutes (fix code) ou immÃ©diat (upgrade plan)  
**PrioritÃ©:** ðŸŸ¡ P2 (Medium)

---

### Incident 4: Redis Unreachable

**SymptÃ´mes:**
- `/health/ready` retourne `"redis": false`
- Logs: `RedisError: Connection refused`
- API fonctionne mais trÃ¨s lente (no cache)

**Causes:**
- Upstash maintenance
- RÃ©seau Render â†’ Upstash bloquÃ©
- Quota Free tier dÃ©passÃ©
- Mauvaise config `REDIS_URL`

**Diagnostic:**
```bash
# 1. VÃ©rifier status Upstash
# https://status.upstash.com/

# 2. Tester connexion Redis
redis-cli -u $REDIS_URL PING
# Should return "PONG"

# 3. VÃ©rifier quota
# Upstash Dashboard â†’ Database â†’ Metrics
# Daily Requests < 10,000 (Free tier)
```

**Actions:**
1. **Upstash maintenance:** Attendre fin maintenance (check status page)
2. **RÃ©seau bloquÃ©:** RedÃ©marrer service Render (restart manual)
3. **Quota dÃ©passÃ©:**
   - Upgrade plan Pay-As-You-Go ($0.002/10k req)
   - Ou rÃ©duire cache usage (augmenter TTL)
4. **Mauvaise config:**
   ```bash
   # Render Dashboard â†’ Environment Variables
   # VÃ©rifier REDIS_URL format:
   # rediss://default:PASSWORD@HOST:6379
   ```

**Temps de RÃ©solution:** 5-30 minutes  
**PrioritÃ©:** ðŸŸ¡ P2 (Medium) - API degraded mais fonctionne

---

### Incident 5: Database Connection Exhausted

**SymptÃ´mes:**
- Logs: `OperationalError: FATAL: remaining connection slots reserved`
- Certaines requÃªtes retournent 500
- `/health/ready` intermittent

**Causes:**
- Pool size trop petit (default: 5 connexions)
- Connexions non fermÃ©es (leak)
- Traffic spike

**Diagnostic:**
```bash
# 1. VÃ©rifier connexions actives PostgreSQL
# Render Dashboard â†’ Database â†’ Metrics â†’ Active Connections
# Si proche de max_connections (default: 97) â†’ problÃ¨me

# 2. Identifier queries longues
SELECT pid, now() - pg_stat_activity.query_start AS duration, query
FROM pg_stat_activity
WHERE state = 'active'
ORDER BY duration DESC;
```

**Actions:**
1. **Augmenter pool size (fix permanent):**
   ```python
   # backend/src/db/database.py
   engine = create_async_engine(
       settings.database_url,
       pool_size=20,  # 5 â†’ 20
       max_overflow=10,
       pool_pre_ping=True,
       pool_recycle=3600,
   )
   ```

2. **Tuer connexions bloquÃ©es (fix temporaire):**
   ```sql
   -- Identifier PID de la query
   SELECT pg_terminate_backend(pid)
   FROM pg_stat_activity
   WHERE state = 'active' AND now() - query_start > interval '5 minutes';
   ```

3. **Scale up DB plan:**
   - Starter: 97 connexions max
   - Standard: 200 connexions max

**Temps de RÃ©solution:** 5 minutes (kill) ou 15 minutes (deploy fix)  
**PrioritÃ©:** ðŸ”´ P0 (Critical si prod, P1 si staging)

---

### Incident 6: LLM API Errors (Groq/Anthropic)

**SymptÃ´mes:**
- Logs: `GroqException: Rate limit exceeded` ou `AnthropicException`
- Predictions gÃ©nÃ©rÃ©es sans ajustements LLM
- `/health/ready` retourne `"llm_api": false`

**Causes:**
- Rate limit Groq (gratuit: 30 req/min)
- API key invalide/expirÃ©e
- API externe down (status.groq.com)

**Diagnostic:**
```bash
# 1. VÃ©rifier status API
# Groq: https://status.groq.com/
# Anthropic: https://status.anthropic.com/

# 2. Tester API key
curl -X POST https://api.groq.com/openai/v1/chat/completions \
  -H "Authorization: Bearer $GROQ_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model": "llama-3.3-70b-versatile", "messages": [{"role": "user", "content": "test"}]}'
```

**Actions:**
1. **Rate limit dÃ©passÃ©:**
   - RÃ©duire frÃ©quence d'appel LLM
   - ImplÃ©menter cache LLM (TTL 1h)
   - Utiliser fallback: Groq â†’ Anthropic

2. **API key invalide:**
   ```bash
   # Render Dashboard â†’ Environment Variables
   # RegÃ©nÃ©rer clÃ© sur console.groq.com
   # Mettre Ã  jour GROQ_API_KEY
   ```

3. **API down:**
   - Activer fallback Anthropic
   - Ou dÃ©sactiver ajustements LLM temporairement:
     ```python
     # Ajouter dans src/llm/client.py
     USE_LLM = False  # Emergency fallback
     ```

**Temps de RÃ©solution:** 5-15 minutes  
**PrioritÃ©:** ðŸŸ¡ P2 (Medium) - Predictions fonctionnent sans LLM

---

## Maintenance PlanifiÃ©e

### Mise Ã  Jour de DÃ©pendances Python

**FrÃ©quence:** Mensuel  
**FenÃªtre:** Samedi 02:00-04:00 UTC (faible trafic)

**ProcÃ©dure:**
```bash
# 1. CrÃ©er branche
git checkout -b chore/update-dependencies

# 2. Mettre Ã  jour uv.lock
cd backend
uv sync --upgrade

# 3. Tester localement
uv run pytest tests/ -v

# 4. Deploy sur staging (si disponible)
# 5. VÃ©rifier logs pendant 24h
# 6. Merge et deploy prod
```

---

### Nettoyage Base de DonnÃ©es

**FrÃ©quence:** Trimestriel  
**Objectif:** Supprimer vieux matchs, prÃ©dictions expirÃ©es

**ProcÃ©dure:**
```sql
-- Supprimer matchs > 1 an et status FINISHED
DELETE FROM matches
WHERE status = 'FINISHED'
  AND match_date < NOW() - INTERVAL '1 year';

-- Supprimer prÃ©dictions > 6 mois
DELETE FROM predictions
WHERE created_at < NOW() - INTERVAL '6 months';

-- Vacuum pour rÃ©cupÃ©rer espace
VACUUM FULL ANALYZE;
```

**Temps estimÃ©:** 30 minutes  
**Downtime:** Aucun (VACUUM peut Ãªtre lent)

---

### Nettoyage Vectors Qdrant

**FrÃ©quence:** Mensuel  
**Objectif:** Rester dans Free tier (1GB)

**ProcÃ©dure:**
```python
# Script: backend/scripts/cleanup_vectors.py
from datetime import datetime, timedelta
from src.vector.client import get_qdrant_client

async def cleanup_old_news():
    client = await get_qdrant_client()
    cutoff = datetime.now() - timedelta(days=90)
    
    # Delete vectors older than 90 days
    client.delete(
        collection_name="news",
        points_selector=FilterSelector(
            filter=Filter(
                must=[
                    FieldCondition(
                        key="created_at",
                        range=Range(lt=cutoff.timestamp())
                    )
                ]
            )
        )
    )
    print(f"Deleted vectors older than {cutoff}")

# Run
asyncio.run(cleanup_old_news())
```

---

## Checklists

### Checklist Pre-Deploy

- [ ] Tests passÃ©s localement (`uv run pytest`)
- [ ] Linting OK (`uv run ruff check`, `uv run black --check`)
- [ ] Migrations testÃ©es (`uv run alembic upgrade head`)
- [ ] Variables d'env vÃ©rifiÃ©es (pas de secret en clair)
- [ ] Changelog mis Ã  jour
- [ ] Equipe notifiÃ©e (#deployments Slack)

### Checklist Post-Deploy

- [ ] Health check OK (`/health/ready` retourne 200)
- [ ] Logs vÃ©rifiÃ©s (no ERROR dans les 5 premiÃ¨res minutes)
- [ ] Endpoints critiques testÃ©s (matches, predictions, auth)
- [ ] Performance stable (response time < 200ms)
- [ ] Sentry: aucune nouvelle erreur
- [ ] Monitor pendant 30 minutes

### Checklist Post-Incident

- [ ] Root cause identifiÃ©e et documentÃ©e
- [ ] Fix permanent dÃ©ployÃ© (pas juste workaround)
- [ ] Post-mortem rÃ©digÃ© (template GitHub Issues)
- [ ] Monitoring ajoutÃ© pour dÃ©tecter recurrence
- [ ] Runbook mis Ã  jour avec nouvelle procÃ©dure
- [ ] Equipe formÃ©e sur nouveau process

---

## Annexes

### A. Commandes Utiles

```bash
# Tester endpoint avec timing
curl -w "\nStatus: %{http_code}\nTime: %{time_total}s\n" \
  https://paris-sportif-api.onrender.com/health

# Dump database (backup manuel)
pg_dump $DATABASE_URL > backup_$(date +%Y%m%d).sql

# Restore database
psql $DATABASE_URL < backup_20260205.sql

# Test Redis connection
redis-cli -u $REDIS_URL INFO

# Test Qdrant connection
curl https://2aa5655c-xxx.gcp.cloud.qdrant.io:6333/collections \
  -H "api-key: $QDRANT_API_KEY"
```

---

### B. Contacts Escalation

| Service | Contact | PrioritÃ© |
|---------|---------|----------|
| Render Support | support@render.com | P0/P1 |
| Upstash Support | support@upstash.com | P2 |
| Groq Support | support@groq.com | P2 |
| Football Data API | support@football-data.org | P3 |

---

**DerniÃ¨re rÃ©vision:** 5 fÃ©vrier 2026  
**Prochaine rÃ©vision:** 5 mai 2026 (trimestriel)
